AI PDF Question Answering App (No OpenAI)
This project is a full-stack web app that allows users to upload a PDF document and ask questions about its content through a simple chat interface. It uses local embeddings via Hugging Face's sentence-transformers and FAISS for fast similarity search, enabling context-aware answers without relying on APIs like OpenAI.
ğŸ¯ Project Goal
To demonstrate an end-to-end implementation of:
- File upload and processing
- Chunking and embedding generation using Hugging Face models
- Storing and querying vector embeddings using FAISS
- Retrieving relevant context to answer user queries
ğŸ”§ Tech Stack
Layer	Tech Used
Frontend	React.js, Axios
Backend	FastAPI
Embeddings	Hugging Face sentence-transformers
Vector DB	FAISS
PDF Reader	PyPDF2
Server	Uvicorn
ğŸ“ Folder Structure

project-root/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ utils.py             # PDF parsing, chunking
â”‚   â”œâ”€â”€ rag.py               # Embedding, FAISS logic
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ (React app files)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

ğŸ–¥ï¸ Features

- Upload and parse large PDF documents (tested with 500+ pages)
- Convert document into text chunks
- Generate local embeddings using Hugging Face sentence-transformers
- Use FAISS for fast vector similarity search
- Ask natural language questions about the document
- No OpenAI or paid API dependencies

âš™ï¸ Installation & Setup
ğŸ”¹ 1. Clone the repository

git clone https://github.com/your-username/pdf-question-answering.git
cd pdf-question-answering

ğŸ”¹ 2. Backend Setup

cd backend
pip install -r requirements.txt

ğŸ“„ Sample requirements.txt

fastapi
uvicorn
PyPDF2
faiss-cpu
sentence-transformers

ğŸ”¹ 3. Start the FastAPI server

uvicorn main:app --reload

ğŸ”¹ 4. Frontend Setup (React)

cd frontend
npm install
npm start

ğŸ§  How It Works

1. User uploads a PDF
2. PyPDF2 extracts and splits the text
3. Text chunks are embedded using Hugging Face's sentence-transformers model (e.g., all-MiniLM-L6-v2)
4. FAISS stores those embeddings for fast retrieval
5. On user query:
    - Query is embedded
    - FAISS finds similar chunks
    - Relevant content is returned as the answer

ğŸ§ª Sample Use Case

- Uploads: business_contract.pdf
- Asks: â€œWhat are the payment terms?â€
- Output: System extracts and returns relevant contract clause

ğŸ“Œ To Improve (Ideas)

- [ ] Summarize long answers
- [ ] Add multi-turn conversation memory
- [ ] Add drag-and-drop PDF support
- [ ] User authentication & history

ğŸ™‹ Author

Atul Manoj Shere
ğŸ“§ atulshere18@gmail.com
ğŸ”— GitHub: https://github.com/Atulshere18
ğŸ”— LinkedIn: https://linkedin.com/in/atulshere18

